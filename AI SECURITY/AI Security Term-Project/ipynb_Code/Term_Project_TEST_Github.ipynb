{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TEST CODE\n",
        "\n",
        "학번 : 20192xxxxxx\n",
        "\n",
        "이름 : 전xx\n",
        "\n",
        "test code입니다 train code에서 학습한 모델을 로드하여\n",
        "테스트하고 예측을 합니다."
      ],
      "metadata": {
        "id": "yWM_nSTwGTic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler,OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import joblib"
      ],
      "metadata": {
        "id": "iMwRGDp6jHGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOAHE5g9jHD2",
        "outputId": "d48768df-d9d3-4018-90aa-c8937d27eda2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Now using {device}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjKUKA9WLeV1",
        "outputId": "85a6b5a1-2c60-4ec7-83f5-b2b9a50a704c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now using cuda.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testcode에서 데이터셋 파일 경로 수정하는 곳 입니다\n"
      ],
      "metadata": {
        "id": "ck2b3JuhHWGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#테스트할 파일 로드\n",
        "filepath = '/content/drive/MyDrive/ai보안 데이터셋/test-set.csv'"
      ],
      "metadata": {
        "id": "sn3hVRG5HWmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test code의 전처리 과정\n",
        "\n",
        "1. id 컬럼이 존재하면 해당 컬럼을 ids에 저장 후 id 컬럼을 데이터에서 제거\n",
        "2. id 컬럼이 존재하지 않을시 id가 없다고 None으로 표시\n",
        "3. Train코드랑 비하게 원핫 인코딩이 필요한 범주형 칼럼들을 나열\n",
        "4. Train코드에서 저장한 one_hotencode.pkl, scaler.pkl 파일을 로드하여 인코딩 및 스케일러 준비\n",
        "5. 범주형 변수 제거 및 원핫 인코딩을 한 변수 추가\n",
        "6. 미리 로드한 sclaer파일로 스케일링\n",
        "7. X 타입을 float 32으로 바꿔 모델에 입력할 수 있도록 해주고 X_tensor를 통해 전처리된 데이터를 파이토치의 텐서로 변환\n",
        "8. return_ids가 참이면 id도 같이 반환, 거짓이면 전치리된 데이터만 반환\n",
        "\n",
        "\n",
        "<비고>\n",
        "\n",
        "scaler_save 폴더 있어야합니다!\n",
        "\n",
        "폴더 안에는one_hotencode.pkl, scaler.pkl 파일있어야합니다!"
      ],
      "metadata": {
        "id": "svxLV1gLIMyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 데이터의 전처리\n",
        "def test_process_data(filepath,ids_return = False):\n",
        "    data = pd.read_csv(filepath)\n",
        "\n",
        "    # 'id' 컬럼 처리\n",
        "    if 'id' in data.columns:\n",
        "        ids = data['id'].values\n",
        "        data = data.drop('id', axis=1)\n",
        "    else:\n",
        "        ids = None\n",
        "\n",
        "    # 범주형 변수들\n",
        "    categorical_cols = ['proto', 'service', 'state']\n",
        "\n",
        "    # Train code에서 저장된 onehot_encoder.pkl와 scaler.pkl 로드\n",
        "    onehot_encoder = joblib.load('/content/drive/MyDrive/scaler_save/onehot_encoder.pkl')\n",
        "    scaler = joblib.load('/content/drive/MyDrive/scaler_save/scaler.pkl')\n",
        "\n",
        "    # 원핫 인코딩 범주형 변수들\n",
        "    X_cat = onehot_encoder.transform(data[categorical_cols])\n",
        "\n",
        "    # 범주형 컬럼을 제거 및 원핫 인코딩 컬럼 추가\n",
        "    X = data.drop(columns=categorical_cols)\n",
        "    X = np.concatenate([X.values, X_cat], axis=1)\n",
        "\n",
        "    # 스케일링 처리\n",
        "    X = scaler.transform(X)\n",
        "    X = X.astype(np.float32)\n",
        "\n",
        "    # 텐서로 변환\n",
        "    X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "\n",
        "    # id 를 반환할지 말지 결정\n",
        "    if ids_return:\n",
        "        return X_tensor, ids\n",
        "    else:\n",
        "        return X_tensor"
      ],
      "metadata": {
        "id": "FlRxv6xljHBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TEST 함수\n",
        "\n",
        "예측한 클래스 인덱스 결과를 반환합니다."
      ],
      "metadata": {
        "id": "Xplz5u43Jkrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predic_test(model, test_loader, device):\n",
        "    model.eval()  # 모델 평가\n",
        "    predictions = [] # 예측 결과 저장할 리스트\n",
        "\n",
        "    with torch.no_grad(): # 그래디언계산 방지 및 메모리 사용최적화\n",
        "        for X_batch in test_loader:\n",
        "            X_batch = X_batch[0].to(device)  # 배치에서 특성 데이터를 가져와 디바이스로 이동\n",
        "            outputs = model(X_batch)  # 모델을 통해 출력값 계싼\n",
        "            _, predicted = torch.max(outputs, 1)  # 예측한 클래스의 가장 큰 값 인덱스를 얻음\n",
        "            predictions.extend(predicted.cpu().numpy())  # 예측한 값을 넘파이로 반환해 예측 리스트에 추가\n",
        "\n",
        "    return predictions # 최종 예측결과 반환"
      ],
      "metadata": {
        "id": "lxB9CtZujG-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TEST CODE의 모델 정의\n",
        "\n",
        "Test code에서도 Train code에서 사용한 코드를 정의합니다.\n",
        "\n",
        "Test code도 train code에서 사용한 모델과 똑같이 정의해야합니다."
      ],
      "metadata": {
        "id": "ONIgK720Hy8c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN 모델 정의\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        # Conv1D 층\n",
        "        self.conv1 = nn.Conv1d(1, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv1d(64, 128, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv1d(128, 256, kernel_size=3, padding=1)\n",
        "\n",
        "        # 풀링 층\n",
        "        self.pool = nn.MaxPool1d(2)\n",
        "\n",
        "        #  완전 연결 층\n",
        "        self.fc1 = nn.Linear(256 * (input_size // 16), 512)  # input_size // 16은 4개의 풀링 레이어에서 줄어든 크기\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "\n",
        "        # 출력층\n",
        "        self.fc3 = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Conv1D 입력을 위한 채널 추가\n",
        "        x = x.unsqueeze(1)\n",
        "\n",
        "        # Conv1D + ReLU + 풀링\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.pool(x)\n",
        "\n",
        "        # Flatten (배치 크기 및 특징을 펼침)\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # 완전 연결층 + ReLU\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "\n",
        "        # 출력층\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "cx9s94Z0jG8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 테스트 데이터 전처리 및 데이터셋 생성"
      ],
      "metadata": {
        "id": "yNRtMHH3Zptw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 데이터 처리\n",
        "X_test, ids = test_process_data(filepath, ids_return = True)\n",
        "X_test_dataset = TensorDataset(X_test)\n",
        "X_test_loader = DataLoader(X_test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "4WjpXu9Tq6Nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습 모델 로드 및 테스트 데이터에 대한 모델 예측\n",
        "\n",
        "Train code에서 학습한 모델을 로드 및 테스트 데이터에 대한 예측을 수행합니다.\n",
        "\n",
        "train_save 폴더에서 cnn_mode_epoch.pth를 로드합니다\n",
        "\n",
        "<비고>\n",
        "\n",
        "train_save 폴더가 있어야 합니다.\n",
        "\n",
        "학습한 모델 가중치도 있어야합니다"
      ],
      "metadata": {
        "id": "fZgqMuqaZB00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 로드\n",
        "model = CNN(input_size=X_test.shape[1], num_classes=10)  # 출력수는 10개\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/train_save/cnn_model_epoch.pth'))\n",
        "model.to(device)\n",
        "\n",
        "#모델 예측\n",
        "test_predictions = predic_test(model, X_test_loader, device)"
      ],
      "metadata": {
        "id": "7MC4GlXhpJTp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc83ce22-f046-4db9-9076-416bf45ec5d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-104-0aee29f8801a>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('/content/drive/MyDrive/train_save/cnn_model_epoch.pth'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# attack_cat의 갯수 확인.\n",
        "\n",
        "예측한 데이트에서 각각의 공격 카테고리가\n",
        "얼마나 발생했는지 숫자로 확인합니다."
      ],
      "metadata": {
        "id": "0FEz8K-xD_Up"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmg-PulEhiMH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45dd0c82-44cd-4f31-9f45-e08b4a8ea36c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack_cat counts:\n",
            "Normal: 27750 samples\n",
            "Fuzzers: 12236 samples\n",
            "Analysis: 373 samples\n",
            "Backdoor: 1 samples\n",
            "DoS: 422 samples\n",
            "Exploits: 18851 samples\n",
            "Generic: 18045 samples\n",
            "Reconnaissance: 4164 samples\n",
            "Shellcode: 490 samples\n",
            "Worms: 0 samples\n"
          ]
        }
      ],
      "source": [
        "#공격유형 카테고리 - 정상 공격 normal를 포함한 9가지 공격유형\n",
        "attack_categories = ['Normal', 'Fuzzers', 'Analysis',\n",
        "                     'Backdoor', 'DoS', 'Exploits', 'Generic',\n",
        "                     'Reconnaissance', 'Shellcode', 'Worms']\n",
        "\n",
        "# attack_cat별 예측 개수 확인\n",
        "category_counts = {category: 0 for category in attack_categories}\n",
        "for pred in test_predictions:\n",
        "    category = attack_categories[pred]  # attack_cat에대한 예측 매핑\n",
        "    category_counts[category] += 1\n",
        "\n",
        "# attack_Cat별 예측 개수 출력\n",
        "print(\"attack_cat counts:\")\n",
        "for category, count in category_counts.items():\n",
        "    print(f'{category}: {count} samples')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 예측한 데이터 저장\n",
        "\n",
        "예측한 데이터를 id와 매핑하여 submisstion 값을 채우며\n",
        "\n",
        "파일을 저장합니다.\n",
        "\n",
        "그리고 그 예측한 값을 실제 레이블이 있는 값과 비교하여\n",
        "\n",
        "잘 예측이 되었는지 정확도를 측정합니다."
      ],
      "metadata": {
        "id": "MtViN1AJMvri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측된 결과를 'id'와 매핑하여 submission 파일 생성\n",
        "predicted_categories = [attack_categories[pred] for pred in test_predictions]\n",
        "submission_df = pd.DataFrame({'id': ids, 'attack_cat': predicted_categories})"
      ],
      "metadata": {
        "id": "_c2EiHEaR3Bv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 저장할 경로 지정 파일이름 설정\n",
        "save_path = '/content/drive/MyDrive/Test_result'\n",
        "file_name = 'submission.csv'\n",
        "\n",
        "# 경로가 존재하지 않으면 폴더 생성\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# 파일 전체 경로\n",
        "full_path = os.path.join(save_path, file_name)\n",
        "\n",
        "# 파일 저장\n",
        "submission_df = pd.DataFrame({'id': ids, 'attack_cat': predicted_categories})\n",
        "submission_df.to_csv(full_path, index=False)\n",
        "print(f\"Submission saved to {full_path}\")\n"
      ],
      "metadata": {
        "id": "jq0tIz5olNGI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10efe831-726c-49c8-8d6c-a5f2bf4b9be5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission saved to /content/drive/MyDrive/Test_result/submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 실제있는 데이터와 비교\n",
        "submission_path = '/content/drive/MyDrive/Test_result/submission.csv'\n",
        "submission = pd.read_csv(submission_path)\n",
        "\n",
        "true_labels_path = '/content/drive/MyDrive/ai보안 데이터셋/UNSW_NB15_testing-set.csv'\n",
        "true_labels = pd.read_csv(true_labels_path)\n",
        "\n",
        "\n",
        "# 'id'와 'attack_cat'을 기준으로 정확도 계산\n",
        "accuracy = accuracy_score(true_labels['attack_cat'], submission['attack_cat'])\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "68mwV6Ithn05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dd808ea-9c4c-4a4f-9f1b-a995668beed8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 75.05%\n"
          ]
        }
      ]
    }
  ]
}